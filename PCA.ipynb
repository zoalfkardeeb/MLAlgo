{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "594ed922b0a92d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:46:06.273284Z",
     "start_time": "2024-05-17T20:46:06.056286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.ensemble import RandomForestClassifier  #Random Forest algorithm\n",
    "from sklearn.manifold import TSNE"
   ],
   "id": "9ba1090e16e9860f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#...........................................................\n",
    "#........Introduction.......................................\n",
    "# In this work PCA for dimensionally reduction is applied\n",
    "#  MNIST dataset is used.  MNIST contains\n",
    "# 28*28 images of handwritten digits. The goal is to show that not all\n",
    "#  28*28=784 features are needed to classify the digits.\n",
    "#..........................................................\n",
    "# Loading mnist train dataset and dividing it into x_train and y train"
   ],
   "id": "49597647cffe328a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:29:47.626803Z",
     "start_time": "2024-05-17T20:29:44.736282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train =pd.read_csv(\"mnist_train.csv\")\n",
    "y_train = x_train['label']\n",
    "del x_train['label']\n",
    "# Loading mnist test dataset and dividing it into x_train and y train\n",
    "x_test  =pd.read_csv(\"mnist_test.csv\")\n",
    "y_test  = x_test['label']\n",
    "del x_test['label']"
   ],
   "id": "e658c29e8acacd0c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:29:49.284383Z",
     "start_time": "2024-05-17T20:29:49.274388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ],
   "id": "e7fcee8530cbe37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#......................using all features.......................\n",
    "# Linear Support Vector Machine (SVM) with all the 784 pixels of the MNIST images is used.\n",
    "# a pipeline is set up  where scale is first applied, and then the classifier"
   ],
   "id": "48d61de43c6f4a59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:36:05.694308Z",
     "start_time": "2024-05-17T20:29:52.429937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps = [('scaling', StandardScaler()), ('clf', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "# train\n",
    "t0 = time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred = pipeline.predict(x_test)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# time taken\n",
    "t_all_feats = time() - t0\n",
    "print(\"Training and classification done in {}s\".format(t_all_feats))"
   ],
   "id": "1561aca44d45029a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.966 \n",
      "\n",
      "[[ 968    0    1    1    0    3    3    2    2    0]\n",
      " [   0 1127    3    0    0    1    2    0    2    0]\n",
      " [   5    1  996    2    2    0    1   15    9    1]\n",
      " [   0    0    4  979    1    7    0   12    7    0]\n",
      " [   0    0   12    0  944    2    4    7    3   10]\n",
      " [   2    0    1   10    2  854    6    8    7    2]\n",
      " [   6    2    1    0    4    8  930    2    5    0]\n",
      " [   1    6   13    2    3    0    0  990    0   13]\n",
      " [   3    0    4    6    6    9    3   14  926    3]\n",
      " [   4    6    5   11   12    2    0   20    3  946]]\n",
      "Training and classification done in 373.257372379303s\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#.........................using PCA..................................................\n",
    "# The next step is to train and predict using a dataset reduced with PCA,\n",
    "# the number of components for the PCA model is reduced to 20."
   ],
   "id": "f53e0919af74033d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:36:50.458444Z",
     "start_time": "2024-05-17T20:36:18.943331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define pipeline steps\n",
    "steps = [('scaling', StandardScaler()), ('reduce_dim', PCA(n_components=20)), ('clf', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "# train\n",
    "t0 = time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred = pipeline.predict(x_test)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "t_reduced_feats = time() - t0\n",
    "print(\"Training and classification done in {}s\".format(t_reduced_feats))\n",
    "print(\"Speedup {}x\".format(t_all_feats/t_reduced_feats))"
   ],
   "id": "6ce163924d110031",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.962 \n",
      "\n",
      "[[ 968    0    2    0    0    3    4    1    2    0]\n",
      " [   0 1126    3    0    1    1    1    0    3    0]\n",
      " [   3    1 1002    4    2    2    2    6    8    2]\n",
      " [   0    0    0  969    1    7    1    8   20    4]\n",
      " [   0    1    5    0  944    1    4    3    1   23]\n",
      " [   1    0    0   16    3  852    9    2    7    2]\n",
      " [   6    3    0    0    4    8  933    0    4    0]\n",
      " [   1    7   13    1    7    0    0  972    1   26]\n",
      " [   4    1    6   13    6   13    2    7  918    4]\n",
      " [   3    6    2   13   24    4    0   16    5  936]]\n",
      "Training and classification done in 31.4891095161438s\n",
      "Speedup 11.853538512670289x\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#...................................Discussion..............................\n",
    "# We get >11x speedup when preprocessing with PCA and an accuracy score\n",
    "# that's quite comparable to having the whole dataset."
   ],
   "id": "1e043739ae2c697"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "27a21db95f86d2ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#.........................using FastICA..................................................\n",
    "# The next step is to train and predict using a dataset reduced with FastICA,\n",
    "# the number of components for the FastICA model is reduced to 20.\n"
   ],
   "id": "bc4022bc8fe3568d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:38:39.578275Z",
     "start_time": "2024-05-17T20:37:45.190343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define pipeline steps\n",
    "steps = [('scaling', StandardScaler()), ('reduce_dim', FastICA(n_components=20)), ('clf', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "# train\n",
    "t2 = time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred = pipeline.predict(x_test)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "t_reduced_feats = time() - t2\n",
    "print(\"Training and classification done in {}s\".format(t_reduced_feats))\n",
    "print(\"Speedup {}x\".format(t_all_feats/t_reduced_feats))"
   ],
   "id": "59e353dda8b13ced",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9258 \n",
      "\n",
      "[[ 955    0    2    1    1    6    8    3    4    0]\n",
      " [   0 1119    3    8    0    1    1    0    3    0]\n",
      " [   9    1  955   37    7    4    2    4   12    1]\n",
      " [   1   10   17  907    7   10    2   13   33   10]\n",
      " [   2    0    7    3  925    2    3    4    4   32]\n",
      " [  12    0    2   27   10  794   11    5   28    3]\n",
      " [   5    5    4    3    6   27  902    1    5    0]\n",
      " [   0    7   14    6   13    2    0  934    2   50]\n",
      " [   5    1    8   25    8   27   10    7  877    6]\n",
      " [   3    6    2   19   45    5    1   31    7  890]]\n",
      "Training and classification done in 54.37892937660217s\n",
      "Speedup 6.864007376723122x\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#...................................Discussion..............................\n",
    "# We get >6x speedup when preprocessing with ICA and an accuracy score\n",
    "# that's quite comparable to having the whole dataset.\n"
   ],
   "id": "96bcbc79146dab21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "db41e283b364a7e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:46:18.479321Z",
     "start_time": "2024-05-17T20:46:16.947789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#......................using all features.......................\n",
    "rf=RandomForestClassifier(n_estimators=3)\n",
    "#training random Forest\n",
    "t0 = time()\n",
    "rf.fit(x_train,y_train)\n",
    "pred=rf.predict(x_test)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=pred), \"\\n\")\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=pred))\n",
    "t_all_feats = time() - t0\n",
    "print(\"Training and classification done in {}s\".format(t_all_feats))"
   ],
   "id": "3dcff17c0f7b7e66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8834 \n",
      "\n",
      "[[ 961    1    3    2    1    3    3    3    2    1]\n",
      " [   1 1120    2    1    0    2    2    1    4    2]\n",
      " [  33   20  913   15    7    5    5   17   14    3]\n",
      " [  13    9   43  882    5   22    3    6   23    4]\n",
      " [  12   10   24   11  876    3    6    5    5   30]\n",
      " [  27   10   19   67   16  724    6    5   14    4]\n",
      " [  23   12   21   11   18   16  849    0    7    1]\n",
      " [   5   15   36    5   13    2    2  920    6   24]\n",
      " [  34   11   45   56   24   23   11    2  756   12]\n",
      " [  12   14   24   33   45   18    2   19    9  833]]\n",
      "Training and classification done in 1.522531270980835s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#.........................using PCA..................................................\n",
    "# The next step is to train and predict using a dataset reduced with PCA,\n",
    "# the number of components for the PCA model is reduced to 20.\n"
   ],
   "id": "7018055a8b7cf249"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:47:26.972296Z",
     "start_time": "2024-05-17T20:47:23.334453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=20)\n",
    "pca.fit(x_train)\n",
    "train_pca = pca.transform(x_train)\n",
    "test_pca = pca.transform(x_test)\n",
    "# train\n",
    "t1 = time()\n",
    "rf.fit(train_pca,y_train)\n",
    "y_pred=rf.predict(test_pca)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "t_reduced_feats_PCA = time() - t1\n",
    "print(\"Training and classification done in {}s\".format(t_reduced_feats_PCA))\n",
    "print(\"Speedup {}x\".format(t_all_feats/t_reduced_feats_PCA))"
   ],
   "id": "c0effbc01965d951",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8667 \n",
      "\n",
      "[[ 923    3   18    8    1    9   10    1    4    3]\n",
      " [   4 1115    4    3    1    2    1    1    3    1]\n",
      " [  34   11  917   22   16    2    5    6   17    2]\n",
      " [  17    6   41  884    2   19    2    8   30    1]\n",
      " [  11    4   26    7  860    2    9    7    4   52]\n",
      " [  31   10   21   66   23  702    9    5   19    6]\n",
      " [  25    9   22    5   16   22  848    2    6    3]\n",
      " [  10   15   36   11   21    4    3  887    6   35]\n",
      " [  44    8   50   55   13   32    7    8  745   12]\n",
      " [  16    8   24   22  106    9    4   24   10  786]]\n",
      "Training and classification done in 1.1006507873535156s\n",
      "Speedup 1.383300942019693x\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#...................................Discussion..............................\n",
    "# We get >1.38x speedup when preprocessing with PCA and an accuracy score is better"
   ],
   "id": "59c060ddefbe6fc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# #.........................using ICA..................................................\n",
    "# # The next step is to train and predict using a dataset reduced with fastICA,\n",
    "# # the number of components for the fastICA model is reduced to 20."
   ],
   "id": "4601a3a798b929b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:48:42.543866Z",
     "start_time": "2024-05-17T20:48:26.853698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ica = FastICA(n_components=20)\n",
    "ica.fit(x_train)\n",
    "train_ica = ica.transform(x_train)\n",
    "test_ica = ica.transform(x_test)\n",
    "# train\n",
    "t2 = time()\n",
    "rf.fit(train_ica,y_train)\n",
    "y_pred=rf.predict(test_ica)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "t_reduced_feats_ica = time() - t2\n",
    "print(\"Training and classification done in {}s\".format(t_reduced_feats_ica))\n",
    "print(\"Speedup {}x\".format(t_all_feats/t_reduced_feats_ica))"
   ],
   "id": "1c03e773a5809971",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\MOLabs\\MOLabs\\.venv\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8432 \n",
      "\n",
      "[[ 940    0    9    7    1   11    9    2    1    0]\n",
      " [   0 1119    7    3    1    0    1    0    3    1]\n",
      " [  34   10  895   40    9    7    5   10   18    4]\n",
      " [  24    9   87  796    6   39    5   10   26    8]\n",
      " [   9   15   26   20  824    5   12   10   10   51]\n",
      " [  30   10   31   80   17  679   12    5   22    6]\n",
      " [  37    7   23   14   30   14  827    1    5    0]\n",
      " [   7   11   46   21   21    3    0  890    6   23]\n",
      " [  21   15   61   74   36   45   13   10  687   12]\n",
      " [  19    5   25   34   81   32    6   21   11  775]]\n",
      "Training and classification done in 1.501979112625122s\n",
      "Speedup 1.0136833849305615x\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# We get >1.03x speedup when preprocessing with FastICA and an accuracy score is better",
   "id": "da808e1673bed97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#...................................Discussion..............................\n",
    "# The results after using SVM and RandomForest as follows\n",
    "# - While using SVM and RandomForest, when we look at the time taken, we can see that PCA is better than FactICA and better than using all features,\n",
    "# and when we look at the accuracy, we can see that the accuracy is not notable affected while using PCA and FactICA  "
   ],
   "id": "75f5be2eb3ae287f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b882de5965121918"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
